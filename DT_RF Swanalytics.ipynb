{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86e7aba-d251-45b1-b135-be2eb8428db9",
   "metadata": {},
   "source": [
    "# Swanalytics - Swan Telecom \n",
    "\n",
    "Using Decision Trees and Random Forest to make predictions on customers most likely to churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a8406-4308-435e-ae76-5702cd78aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time  # For timing model runs\n",
    "\n",
    "# Sklearn - model selection & evaluation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import metrics  # Optional if you're using things like metrics.classification_report\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import tree\n",
    "\n",
    "# Random Forest & Extra Trees\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ET\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4bb5b9-9bbc-4d9d-ad6e-31f9b3307c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gdiwa23/Swanalytics/refs/heads/main/1%20Project%20Data%20-%20Telco_Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484d490c-e6da-47b0-9c05-56eebec19bd6",
   "metadata": {},
   "source": [
    "### first look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51229543-b88f-47ec-9d25-169a54e58aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f6dbd-ef8a-4cd5-b574-5deb3fdcbb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5a4d4-2db5-47b9-906b-a641a2951bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20086d8-19ef-4b2e-93ec-0b6d5829ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4824b-6ff3-4c2d-ba70-5099b3745241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb872c8c-f872-4b5f-a7af-bc9912475ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() / len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3510110-908f-4c7c-a18b-822385b5bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0e46a-af57-48e3-acd3-9f93fa008672",
   "metadata": {},
   "source": [
    "*  After a first look at the data, the following actions must be taken to clean up the df, in preparation for train test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2476bf-a535-45be-bee7-63aa4c71fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Count\",\"City\",\"Country\",\"State\",\"Lat Long\",\"Churn Label\",\"Churn Reason\"]) # drop columns we don't want to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec278df-6adc-4fdb-ab96-1eefcea3ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total charges needs to be cast to float\n",
    "\n",
    "df['Total Charges'] = pd.to_numeric(df['Total Charges'], errors='coerce') # casts to float\n",
    "df['Total Charges'] = df['Total Charges'].fillna(0) # found NaN values after casting -> fill with 0\n",
    "df['Total Charges'].isnull().sum() # check = 0 nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a30d764-e6fb-4ef1-bc3c-ba440c447aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('CustomerID', inplace=True) # set as index, checked all are unqiue first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5866ec8-cb53-499a-8c65-5a7a392378a1",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4f29b-1eea-4595-af51-7a19aab442e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# set feature columns\n",
    "feature_cols = df.columns.drop('Churn Value')\n",
    "#feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76912a-ada4-4631-bd1a-0bec3de78c42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# set X and y \n",
    "X = df[feature_cols].copy()  # features\n",
    "y = df['Churn Value']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd90018-f667-473a-a7e5-283cc1d82539",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ae387-ff5a-4432-8d45-ae26c93ed6c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "print(f'Train match: {len(X_train)==len(y_train)}')\n",
    "print(f'Test match: {len(X_test)==len(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac2bf75-71b5-4657-839a-02c268329e5e",
   "metadata": {},
   "source": [
    "### Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966167ef-0d06-4604-9b85-a1e4625c9755",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# func for cleaning \n",
    "def clean_data(df):\n",
    "\n",
    "  assert isinstance(df, pd.DataFrame), 'Parameter needs to be a DataFrame'\n",
    "    \n",
    "  df_clean = df.copy() # df is X\n",
    "\n",
    "\n",
    "  # OHE the service column into Fibre Optic or DSL - 0 in both indicates no internet service\n",
    "    \n",
    "  service_dummies = pd.get_dummies(df_clean['Internet Service'], prefix='Service', drop_first=True, dtype=int)\n",
    "  df_clean = pd.concat([df_clean, service_dummies], axis=1)\n",
    "  df_clean = df.drop(columns=['Internet Service'])\n",
    "\n",
    "  df_clean = pd.get_dummies(df_clean, columns = ['Contract'], drop_first = True, prefix = 'Contract', dtype = int)\n",
    "  df_clean = pd.get_dummies(df_clean, columns=['Payment Method'], drop_first=True, prefix='Payment_Method', dtype=int)\n",
    "\n",
    "\n",
    "    \n",
    "  # Label Encoding\n",
    "\n",
    "  df_clean['Gender'] = df_clean['Gender'].map({'Female': 0, 'Male':1, 0:0, 1:1})\n",
    "  df_clean['Senior Citizen'] = df_clean['Senior Citizen'].map({'No': 0, 'Yes':1, 0:0, 1:1})\n",
    "  df_clean['Partner'] = df_clean['Partner'].map({'No': 0, 'Yes':1, 0:0, 1:1})\n",
    "  df_clean['Dependents'] =  df_clean['Dependents'].map({'No': 0, 'Yes':1, 0:0, 1:1})\n",
    "  df_clean['Phone Service'] = df_clean['Phone Service'].map({'No': 0, 'Yes':1, 0:0, 1:1})\n",
    "  df_clean['Multiple Lines'] = df_clean['Multiple Lines'].map({'No': 0, 'Yes':1,'No phone service':0, 0:0, 1:1})\n",
    "\n",
    "  df_clean['Online Security'] = df_clean['Online Security'].map({'No':0, 'Yes':1, 'No internet service':0, 0:0, 1:1})\n",
    "  df_clean['Online Backup'] = df_clean['Online Backup'].map({'No':0, 'Yes':1, 'No internet service':0, 0:0, 1:1})\n",
    "  df_clean['Device Protection'] = df_clean['Device Protection'].map({'No':0, 'Yes':1, 'No internet service':0, 0:0, 1:1})\n",
    "  df_clean['Tech Support'] = df_clean['Tech Support'].map({'No':0, 'Yes':1, 'No internet service':0, 0:0, 1:1})\n",
    "\n",
    "  #TV - No internet service has been combined with No\n",
    "  df_clean['Streaming TV'] = df['Streaming TV'].replace(['No internet service', 'No'], 'No')\n",
    "  df_clean['Streaming TV'] = df_clean['Streaming TV'].map({'No': 0, 'Yes':1, 0:0, 1:1})\n",
    "  # Movies- No internet service has been combined with No\n",
    "  df_clean['Streaming Movies'] = df['Streaming Movies'].replace(['No internet service', 'No'], 'No')\n",
    "  df_clean['Streaming Movies'] = df_clean['Streaming Movies'].map({'No': 0, 'Yes':1, 0:0, 1:1})\n",
    "  # Paperless Billing\n",
    "  df_clean['Paperless Billing'] = df_clean['Paperless Billing'].map({'No': 0, 'Yes':1, 0:0, 1:1})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d55a6f-d4e2-491f-8183-59a356ebc9ac",
   "metadata": {},
   "source": [
    "#### clean the data using the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a001db-aed3-4287-9bae-ca67ba084b86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_train_fe = clean_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb79a29-fb4d-49e8-b59a-53107e50ce60",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_test_fe = clean_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955de1a-d45f-408f-8708-66403fa3c225",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## no churn DATA TO PREDICT ON \n",
    "df_nochurn = df[df['Churn Value'] ==  0]\n",
    "df_nochurn = df_nochurn.drop(columns=[\"Churn Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab50e1a-39e3-4a24-a7de-8e83a9a08d07",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_nochurn = df_nochurn[feature_cols]\n",
    "df_nochurn_fe = clean_data(df_nochurn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742dcffe-1979-49c0-bf57-9d5d7be5e7f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks - just to make sure all good\n",
    "\n",
    "print(f'Train post split match: {len(X_train_fe)==len(y_train)}')\n",
    "print(f'Test post split match: {len(X_test_fe)==len(y_test)}\\n')\n",
    "\n",
    "print(f'Train post data cleaning match: {X_train_fe.shape[0] == X_train.shape[0]}')\n",
    "print(f'Test post data cleaning match: {X_test_fe.shape[0] == X_test.shape[0]}\\n')\n",
    "\n",
    "print(f'Churn data post cleaning match: {df_nochurn_fe.shape[0]==df_nochurn.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c0119-f918-4eb4-a7b6-295771ee05b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a87f033c-3854-46a3-9f9c-9d6c47bba492",
   "metadata": {},
   "source": [
    "### Decision Tree + Grid Search\n",
    "\n",
    "* Start with the initial decision tree and use as benchmark.\n",
    "\n",
    "* The decision tree achieves a solid 79% accuracy on the training set, but deeper analysis reveals that while precision is acceptable at 68%, recall is significantly lower at 42%. This suggests the model is better at correctly identifying churners when it predicts churn BUT misses a large portion of actual churners. Improving recall and precision are key in order to maximise the models ability to predict churners and optimise Market Team's efforts in targetting churners.\n",
    "* With a limited slot of just Top 500 to deliver to the Marketing Team, we need to focus on Precision and Recall as metrics to ensure that the model captures customers who are most likely to churn.\n",
    "* This leads into the use of grid search to optimise parameters\n",
    "\n",
    "\n",
    "> Decision Tree Key Metrics: Train Set  \n",
    "> \n",
    "> Accuracy:   0.7903798367057153  \n",
    "> Precision:  0.6801705756929638  \n",
    "> Recall:     0.42001316655694537  \n",
    "> F1:         0.5193325193325193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c925d5-cde3-41ec-99d3-e18f8331b356",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# first decision tree\n",
    "dt = DecisionTreeClassifier(max_depth=4, # initially 3, but changed to 4 and saw improvement\n",
    "                            random_state=2)\n",
    "dt.fit(X_train_fe, y_train) #fit data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc0b03-cbda-43f2-9373-cc2900068124",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plot the first tree\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "tree_1 = tree.plot_tree(dt,\n",
    "                   feature_names=X_train_fe.columns,\n",
    "                   class_names=['Churned', 'Stayed'],\n",
    "                   filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f3fd3-5309-4826-b7e7-525cae1f32e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## accuracy score ## 0.79 and 0.79 , not bad\n",
    "print(f'Score on training set: {dt.score(X_train_fe, y_train)}')\n",
    "print(f'Score on testing set: {dt.score(X_test_fe, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fdb50-af5b-4856-b01c-ee98cb93c245",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def apr(y_real, y_pred):\n",
    "    \"\"\" Calculates accuracy, precision, recall\n",
    "        Requires predicted value first, and then the real value\n",
    "    \"\"\"\n",
    "    accuracy = metrics.accuracy_score(y_real, y_pred)\n",
    "    precision = metrics.precision_score(y_real, y_pred)\n",
    "    recall = metrics.recall_score(y_real, y_pred)\n",
    "    f1 = metrics.f1_score(y_real, y_pred)\n",
    "\n",
    "    print(f\"Accuracy:   {accuracy}\")\n",
    "    print(f\"Precision:  {precision}\")\n",
    "    print(f\"Recall:     {recall}\")\n",
    "    print(f\"F1:         {f1}\")\n",
    "    #return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49bcb2-2f5a-4b0d-9d95-cfaafa1188b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Decision tree 1 key metrics \n",
    "\n",
    "y_pred_dt = dt.predict(X_train_fe) # add y_pred col # decision tree pred\n",
    "print('Decision Tree Key Metrics: Train Set\\n')\n",
    "apr(y_train, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c72cc0a-1c69-4f7c-a00e-836637477a43",
   "metadata": {},
   "source": [
    "#### Grid Search with DT\n",
    "* To improve on the intial results of the dt, we are using grid search in order to optimise the hyperparameters used in the model\n",
    "* cv = 10 , means that the grid search will cross validate across 10 slices the data \n",
    "* grid search will give us the .best_estimator_ which will be used to train the data\n",
    "\n",
    "* The Random Forest model achieves an accuracy of 80.7%, indicating solid overall performance. With a precision of 63.8%, it reliably identifies actual churners when it predicts churn. A recall of 65.1% shows the model captures a good portion of actual churn cases, better than the decision tree. The F1 score of 64.5% reflects a balanced trade-off, making this model suitable for churn detection with moderate risk tolerance.\n",
    "\n",
    ">  Decision Tree (+GridSearch) Key Metrics: Train Set\n",
    "> * Accuracy:   0.8065317713880015\n",
    "> * Precision:  0.6384764364105875\n",
    "> * Recall:     0.6510862409479921\n",
    "> * F1:         0.6447196870925684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f89c7-4147-4d15-96d3-151466719f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid searach\n",
    "grid = GridSearchCV(estimator = DecisionTreeClassifier(random_state=2),\n",
    "                                   param_grid = {'max_depth': [5, 7, 10],                   # the options you want to explore\n",
    "                                  'min_samples_split': [10, 50, 100, 150, 200], # ''\n",
    "                                  'min_samples_leaf': [2, 3, 4, 5, 6, 7],        # ''\n",
    "                                  'max_features':[2, 3, 4, 5, 6, 7, 8, 10, 12]},      # number of features to use                       ## up max features later\n",
    "                    cv = 5,              # 10 folds, cross validate 10 times\n",
    "                    refit = True,         # refitting = retraining on the K folds , cross validation, swaps\n",
    "                    verbose = 1,          # how much we get told about what went on in the gridsearch\n",
    "                    scoring = 'recall') # changed to recall to maximise this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae0ea39-4aff-4049-8f5c-d916eaa7c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer, to see how long model takes to finish\n",
    "now = time()\n",
    "\n",
    "# fit the model\n",
    "grid.fit(X_train_fe, y_train)     # time between pressing run and model finishing\n",
    "print(f' Time in seconds: {time() - now}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e39eb2-a18d-415d-8644-a5101960902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best version of the DT according to gridsearch -> grid.best_estimator_\n",
    "\n",
    "dt_best_estimator = grid.best_estimator_ # train dt model on grid best estimator\n",
    "dt_best_estimator.fit(X_train_fe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298703a-6529-448d-bf4f-b8c8dc39b5fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dt_best_estimator tree plot\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "thing = tree.plot_tree(dt_best_estimator,\n",
    "                   feature_names=X_train_fe.columns,\n",
    "                   class_names=['Churned', 'Stayed'],\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e5753-9a4e-44ed-aa72-20cb67e07ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â score for training and test\n",
    "\n",
    "print(f'Score on training set: {dt_best_estimator.score(X_train_fe, y_train)}')\n",
    "print(f'Score on testing set: {dt_best_estimator.score(X_test_fe, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2817b4b-dd4f-445f-b926-fe045bd99ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key metrics for Decision Tree + GridSearch\n",
    "\n",
    "y_pred_dt_best_estimator = dt_best_estimator.predict(X_train_fe) # add y_pred col # decision tree pred\n",
    "print('Decision Tree (+GridSearch) Key Metrics: Train Set\\n')\n",
    "apr(y_train, y_pred_dt_best_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70047213-408b-488d-8690-ed347f72f011",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### DT feature importances\n",
    "\n",
    "* Feature importances informs us which features had the most influence in producing the model's predictions.\n",
    "> Top 10 Feature importances \n",
    "> * Monthly Charges: 0.2597\n",
    "> * Payment Method: 0.1938\n",
    "> * Dependents: 0.1410\n",
    "> * Contract: 0.1328\n",
    "> * Paperless Billing: 0.0932\n",
    "> * Tenure Months: 0.0490\n",
    "> * Streaming Movies: 0.0210\n",
    "> * Device Protection: 0.0189\n",
    "> * Latitude: 0.0177\n",
    "> * Longitude: 0.0173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0bae96-789a-46b5-b9f9-4197dad20608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view feature importance ## same as before gs\n",
    "\n",
    "dt_best_estimator.feature_importances_\n",
    "\n",
    "# Pair feature names with their importance values\n",
    "importance = list(zip(feature_cols, dt_best_estimator.feature_importances_))\n",
    "\n",
    "# Sort the list by importance in descending order\n",
    "importance_sorted = sorted(importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display\n",
    "for feature, score in importance_sorted:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "\n",
    "## most important features according to the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36c0a1-367e-4f33-92b7-c2e60e5bcff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame(importance_sorted, columns=[\"feature\", \"score\"])\n",
    "importance_df['score'] = round(importance_df['score'] * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed565253-2218-468e-b6bc-fa565bd386c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_10_dt = sns.barplot(\n",
    "    data=importance_df,\n",
    "    x=importance_df['feature'][:10],\n",
    "    y='score',\n",
    "    color='darkorange'\n",
    ")\n",
    "\n",
    "for spine in features_10_dt.spines.values(): # spine is border of plot\n",
    "    spine.set_color('grey')\n",
    "    spine.set_linewidth(1)\n",
    "\n",
    "plt.xticks(rotation=45, color='grey')        # x-axis tick labels grey\n",
    "plt.yticks(color='grey')                      # y-axis tick labels grey\n",
    "plt.xlabel('Top Features', fontsize=12, color='grey')   # x-label grey\n",
    "plt.ylabel('Score %', fontsize=12, color='grey')        # y-label grey\n",
    "plt.title('Top 10 Feature Importances DT + Grid search (%)', fontsize=14, color='grey')  # title grey\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('features_10_dt_.png', dpi=300, bbox_inches='tight', transparent=False) # transparent !\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e921821-2140-4dc9-b7e2-9b00d411fd99",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "* Ensemble of Decision Trees: Combines multiple decision trees to improve accuracy and control overfitting.\n",
    "* Randomness: Uses bootstrap samples of data + random subsets of features at each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cde90f-ec25-49a4-90a1-eca8077450e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the model\n",
    "rf = RF(n_estimators=100, max_depth=9, random_state=2) # 50 trees, 4 levels of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5509c-0855-4574-b2f2-2ef48bbfbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "rf.fit(X_train_fe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b239c-1ac9-4a97-8d7b-8841630955eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the  accuracy score ! cv = five k fold cross validation !\n",
    "rf_score = cross_val_score(rf, X_train_fe, y_train, cv=10)\n",
    "\n",
    "print(f'The accuracy of RF is: {rf_score}\\n') # all the 10 cv folds\n",
    "print(f'The mean accuracy of RF is: {rf_score.mean()}') # the mean of the 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541b1eb-b9f0-4354-88d0-50f2ab3d5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_score = cross_val_score(rf, X_test_fe, y_test, cv=10)\n",
    "print(f'The mean accuracy of RF is: {rf_test_score.mean()}') # the mean of the 5 -- v good accuracy and not very overfit !!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9d4fa-10ff-44e4-bb0c-60a2f2421a05",
   "metadata": {},
   "source": [
    "### Grid Search on RF \n",
    "* Grid Search on Random Forest to systematically optimise hyperparameters and improve model performance for churn prediction\n",
    "* Random Forest is robust and handles but performance heavily depends on tuning parameters\n",
    "* The main motivation for using Grid Search was to balance recall and precision whilst minimising overfit\n",
    "* added class weight: balanced to grid search to reduce overfit\n",
    "  \n",
    "#### The final version of RF + GS model\n",
    "* The model aims to balance overfitting while maximizing F1 (harmonizing precision and recall).\n",
    "* Tree depth was limited to reduce model complexity.\n",
    "* min_samples_split and min_samples_leaf were increased to encourage generalization and reduce sensitivity to noise.\n",
    "* max_features was restricted to control model greediness and curb overfitting.\n",
    "* class_weight='balanced' ensures fair treatment of the smaller class.\n",
    "* The scoring metric was switched from accuracy to F1 to better reflect the goal of optimizing both precision and recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb1fbe-a2e9-4d09-a590-6484a9d0ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified k fold sampling \n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce798571-c11d-425e-b710-c6828b1c0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(\n",
    "    estimator=RF(random_state=2),\n",
    "    param_grid={\n",
    "            'n_estimators': [100, 200], #number of trees in the forest\n",
    "            'max_depth': [7,8,9],                              # [7, 9, 12]\n",
    "            'min_samples_split': [30,40],                                        # [20, 50, 100]\n",
    "            'min_samples_leaf': [6,8],\n",
    "            'max_features': [0.65], ## make less greedy      # [0.4, 0.6, 0.7]\n",
    "            'class_weight': ['balanced'] ###### added this\n",
    "    },\n",
    "    cv=skf,             # 5-fold cross-validation\n",
    "    refit=True,         # Refits the best model on the whole training set\n",
    "    verbose=1,          # Output the progress\n",
    "    scoring='f1',       # changed to F1 , want to balance precision and recall , guide gs to prioritise this\n",
    "    n_jobs=-1           # parallel running\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d01d64-c97e-493c-8dd4-6bb518578a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time()\n",
    "gs.fit(X_train_fe, y_train)\n",
    "print(f' Time in seconds: {time() - now}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc08ce-7956-416b-95ea-f44232a59876",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e9315-6b8d-4283-a64f-a68a96e42340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get scores\n",
    "\n",
    "rf_best_estimator = gs.best_estimator_\n",
    "print(f'RF train accuracy: {rf_best_estimator.score(X_train_fe, y_train)}')\n",
    "# Use it to score on the testing set\n",
    "print(f'RF test accuracy: {rf_best_estimator.score(X_test_fe, y_test)}')\n",
    "\n",
    "## accuracy is better than the single decision tree (0.79, train), but suggests model is overfit on test\n",
    "## 0.837 , 0.777, ## less over fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6449af-e8e9-42e2-ad26-31509d9ca2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key metrics for Random + GridSearch\n",
    "X_train_rf_results = X_train_fe.copy()\n",
    "\n",
    "\n",
    "y_pred_rf_best_estimator = rf_best_estimator.predict(X_train_fe) # add y_pred col # decision tree pred\n",
    "\n",
    "X_train_rf_results['y_pred'] = y_pred_rf_best_estimator\n",
    "\n",
    "print('Random Forest (+GridSearch) Key Metrics: Train Set\\n')\n",
    "apr(y_train, y_pred_rf_best_estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c84f7-d727-43f6-b633-ed9c4665664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rf_results = X_test.copy()\n",
    "y_pred_rf_best_estimator = rf_best_estimator.predict(X_test_fe) # add y_pred col # decision tree pred\n",
    "X_test_rf_results['y_pred'] = y_pred_rf_best_estimator\n",
    "print('Random Forest (+GridSearch) Key Metrics: Test Set\\n')\n",
    "apr(y_test, y_pred_rf_best_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56da59f8-6b84-46b9-bb9e-6c29a7d135a0",
   "metadata": {},
   "source": [
    "#### feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d13772-7240-40e8-b7c1-50e6492d7181",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## various tuning results -- \n",
    "\n",
    "# Random Forest (+GridSearch) Key Metrics: Train Set\n",
    "# \n",
    "# Accuracy:   0.8452254171104011\n",
    "# Precision:  0.7943585077343039\n",
    "# Recall:     0.5747202106649111\n",
    "# F1:         0.6669213139801375\n",
    "\n",
    "#Random Forest (+GridSearch) Key Metrics: Train Set\n",
    "\n",
    "#Accuracy:   0.818778842740504\n",
    "#Precision:  0.6163551401869158\n",
    "#Recall:     0.8683344305464121\n",
    "#F1:         0.7209620114785461\n",
    "\n",
    "#Random Forest (+GridSearch) Key Metrics: Train Set max feat = 0.6\n",
    "\n",
    "#Accuracy:   0.8315583954561591\n",
    "#Precision:  0.6371511068334937\n",
    "#Recall:     0.8716260697827518\n",
    "#F1:         0.7361690297470114\n",
    "\n",
    "#Random Forest (+GridSearch) Key Metrics: Train Set max feat = 0.75 -- v overfit tho .. \n",
    "#\n",
    "#Accuracy:   0.8358182463613774\n",
    "#Precision:  0.6426512968299711\n",
    "#Recall:     0.8808426596445029\n",
    "#F1:         0.7431269091918912\n",
    "\n",
    "#Random Forest (+GridSearch) Key Metrics: Train Set max feat = 0.7 -- v overfit tho .. \n",
    "#\n",
    "#Accuracy:   0.8374156904508342\n",
    "#Precision:  0.6440516005733397\n",
    "#Recall:     0.8874259381171824\n",
    "#F1:         0.7464008859357697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87decf15-ea2d-43be-9ea8-bfce2f7996ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view feature importance ## same as before gs\n",
    "\n",
    "rf_best_estimator.feature_importances_\n",
    "\n",
    "# Pair feature names with their importance values\n",
    "importance_rf = list(zip(feature_cols, rf_best_estimator.feature_importances_))\n",
    "\n",
    "# Sort the list by importance in descending order\n",
    "importance_sorted_rf = sorted(importance_rf, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display\n",
    "for feature, score in importance_sorted_rf:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "\n",
    "## most important features according to the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1283a4-db71-412c-b0b1-ddadfc483a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_rf_df = pd.DataFrame(importance_sorted_rf, columns=[\"feature\", \"score\"])\n",
    "importance_rf_df['score'] = round(importance_rf_df['score'] * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f2708-70a9-4977-b6ca-d55296159f7c",
   "metadata": {},
   "source": [
    "sns.barplot(data=importance_rf_df, x=importance_rf_df['feature'][:10], y='score', color = 'powderblue')\n",
    "plt.xticks(rotation=45)  # Optional: rotate x-axis labels\n",
    "plt.tight_layout()       # Optional: improve layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b2ae9-8a1f-4fda-8f69-03c04731375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## graph of top 10 features according to RF + grid search model !\n",
    "\n",
    "top10_df = importance_rf_df.iloc[:10]\n",
    "\n",
    "features_10_rf = sns.barplot(\n",
    "    data=top10_df,\n",
    "    x='feature',\n",
    "    y='score',\n",
    "    color='darkorange'\n",
    ")\n",
    "\n",
    "for spine in features_10_rf.spines.values():\n",
    "    spine.set_color('grey')\n",
    "    spine.set_linewidth(1) # grey plot boarder\n",
    "\n",
    "plt.xticks(rotation=45, color='grey')        # x-axis tick labels grey\n",
    "plt.yticks(color='grey')                      # y-axis tick labels grey\n",
    "plt.xlabel('Top Features', fontsize=12, color='grey') # grey\n",
    "plt.ylabel('Score %', fontsize=12, color='grey') # grey\n",
    "plt.title('Top 10 Feature Importances RF + Grid search (%)', fontsize=14, color='grey') # grey\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('features_10_rf.png', dpi=300, bbox_inches='tight', transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4d53f-8059-4477-860b-189b7c9ffd2b",
   "metadata": {},
   "source": [
    "## Final Predictions using RF and Grid Search\n",
    "* top 500 most likely to leave the service have been identified\n",
    "* using a Random Forest model train on X_train_fe, combined with Grid Search to optimise the hyperparameters\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f8080-533b-414f-93fd-77507e775158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy df\n",
    "rf_results = df_nochurn_fe.copy()\n",
    "# predict on no churn\n",
    "rf_results[['P No Churn','P Churn']] = rf_best_estimator.predict_proba(df_nochurn_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398c5f7-8e7b-4a93-8032-23c13f6a372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add y pred to results\n",
    "y_pred_rf_best_estimator = rf_best_estimator.predict(df_nochurn_fe) # add y_pred col # decision tree pred\n",
    "rf_results['y_pred'] = y_pred_rf_best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3deac75-a32b-47e6-b427-b79643026c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"y_pred\",\"P Churn\", \"P No Churn\"\n",
    "rf_results = rf_results[[\"y_pred\",\"P Churn\", \"P No Churn\"]]\n",
    "# sort values by 500 \n",
    "rf_results = rf_results.sort_values(by=['P Churn'] , ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ed519-a2fd-440f-a31d-90570345abad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3780fe1-3f71-4339-9520-aada80ad9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv - top 500 churners by probability from existing customers existing customers, model trained on X_train_fe\n",
    "\n",
    "rf_results.head(500).to_csv('top500_RF.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190cbe1-4af9-49f5-9544-cf28566eebfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
